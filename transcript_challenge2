Team Name :- Project Mayhem

Team Members 
  1. Prajwal Warade
  2. Aditya Sosa
  3. Akash Venkatesh
  4. Shubham Malviya
  5. Sandip Dalvi

Approach of Solving the Problem
1. Understand the Data
	•	Examine class distribution in `train_labels.csv
	•	Visualize a few examples from each category.
	•	Verify for class imbalance (critical).
2. Preprocessing
	•	Resize images (e.g., to 224x224 for ResNet).
	•	Normalize according to ImageNet statistics when using pretrained models.
	•	Augmentations:
	◦	RandomHorizontalFlip, RandomRotation, ColorJitter, etc.
3. Data Loading
	•	Utilize torch.utils.data.Dataset for your own train/test Load data through DataLoader with
	◦	shuffle=True for train
	◦	batch_size=32 or 64
Effective and scalable data pipeline.
4. Model Selection
Transfer learning accelerates convergence and enhances performance when working with smaller data sets.
5. Loss Function
	•	Use BCELoss() for binary classification.
	•	If your data are imbalanced, use `BCEWithLog
Assists to penalize misclassified minority class.
6. Optimizer & Scheduler
	•	Start with Adam optimizer (lr=1e-4).
	•	Use a learning rate scheduler
	◦	StepLR or `Reduce
Improved convergence and adaptive optimization.
7. Training Loop
	•	Correctly use model.train() and `model.eval
	•	Track:
	◦	Loss
	◦	Precision
	◦	F1-score (custom function)
	◦	Epoch time & ETA
Debugging and monitoring enable optimization of training strategy.
8. Validation Strategy
	•	Hold out 10–20% of data for validation. Or utilize Stratified K-Fold Cross-Validation

9. Predictions & Submission
	•	Use model.eval() for inference. Apply threshold = 0.5 to sigmoid output.
	◦	Make and store submission.csv.
Challenges Faced

Class Imbalance
	•	Issue: Most images belong to one class (e.g., soil), while others are rare (non-soil).
	•	Impact: Model predicts the majority class always → high accuracy but poor F1-score.
	•	Solution: Used weighted loss functions or data augmentation on minority class.
Noisy or Low-Quality Images
	•	Issue: Some images may contain unclear textures, background clutter, or poor lighting.
	•	Impact: Hard for the model to learn clear distinguishing features.
	•	Solution: Image enhancement and data augmentation techniques (e.g., brightness, contrast adjustment).
Binary Labels for Multiclass-Looking Data
	•	Issue: Images may visually appear as if they belong to different soil types, but labels are just 0/1.
	•	Impact: Confusion in learning discriminative features.
	•	Solution: Focused on features like texture, color, and patterns; not overfitting to color hue alone.
Overfitting
	•	Issue: Model performs well on training but poorly on validation/test.
	•	Impact: Generalization fails → low public leaderboard score.
	•	Solution: Regularization via dropout, augmentation, early stopping, and validation monitoring.
Runtime Environment Limits
	•	Issue: Kaggle notebook has restricted write access (/kaggle/input is read-only).
	•	Impact: Errors while saving submission files or models.
	•	Solution: Saved files only in /kaggle/working.
Time Constraints
	•	Issue: Short competition window (few days).
	•	Impact: Limited time for extensive experimentation or hyperparameter tuning.
	•	Solution: Prioritized fast prototyping with pretrained models and minimal compute waste.

How did we overcome the challenges
1. Class Imbalance
	•	Challenge: The dataset had more “soil” images than “non-soil”.
	•	Solution:
	◦	Used pos_weight in BCEWithLogitsLoss to balance the loss function.
	◦	Applied data augmentation to increase the diversity of minority class samples (non-soil, if available).
2. Noisy or Low-Quality Images
	•	Challenge: Some images were blurry, had uneven lighting, or cluttered backgrounds.
	•	Solution:
	◦	Performed image preprocessing like resizing, normalization.
	◦	Used data augmentation (RandomHorizontalFlip, ColorJitter, etc.) to make the model more robust to real-world variations.
3. Overfitting
	•	Challenge: Model performed well on training data but poorly on unseen data.
	•	Solution:
	◦	Applied dropout, data augmentation, and early stopping.
	◦	Created a custom validation split from training data to tune model performance.
4. Restricted File System (Kaggle)
	•	Challenge: Could not write files to /kaggle/input.
	•	Solution:
	◦	Changed all output and submission file paths to /kaggle/working/, which is writable in Kaggle Notebooks.
5. Slow Training on CPU
	•	Challenge: Limited compute led to long training times.
	•	Solution:
	◦	Used lightweight models (like ResNet18).
	◦	Reduced image resolution to 224x224 and used smaller batch sizes when needed.
	◦	Minimized epochs and performed sanity checks early.



Final Observation
Soil Image Classification Challenge posed a useful chance to use deep learning methods to solve a real-world binary image classification issue. Through this project, we tried multiple methods for separating images of soil from non-soil images efficiently.
We utilized transfer learning by using pretrained features to bypass a small dataset's constraints and enable better generalizability. Special care was taken toward data preprocessing, augmentation, and balancing methods to counteract image variability problems and imbalanced classes. Focusing on F1-score, not accuracy, led us to optimize the model for balanced performance across both classes.
Despite initial setbacks in terms of noise in the input data, absence of validation splits, and limitations in file systems within the competition environment, systematic debugging, organized experimentation, and explicit code modularity assisted us in developing a stable and reproducible solution.
Ultimately, this project deepened our knowledge of
	•	Practical image classification with CNNs
	•	Fine-tuning pretrained models
	•	Dealing with unbalanced data and noisy labels
	•	Writing neat and submission-ready machine learning code
With additional fine-tuning (e.g., threshold calibration, ensembling, or stacking models), the solution can potentially perform even better. The challenge brought out not solely model performance, however, but code clarity, evaluation approach, and project organization.

Leaderboard
F1 Score :- 0.8288
